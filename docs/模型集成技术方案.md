# 🎵 模型集成技术方案

> **BS-RoFormer 音源分离 + CLaMP 3 语义分析**
> 
> 编写日期：2026-02-07

---

## 一、项目背景

当前 Poly-Muse Analyst 的 Agent 框架已完成，但两个核心 AI 模型仍使用模拟输出：

| 模块 | 当前状态 | 目标 |
|------|----------|------|
| 音源分离 (separator.py) | 占位代码，不输出真实分轨 | 集成 BS-RoFormer，输出 vocals/drums/bass/other |
| 语义分析 (semantic_reviewer.py) | 硬编码模拟标签 | 集成 CLaMP 3，实现真实语义检索 |

---

## 二、BS-RoFormer 音源分离集成方案

### 2.1 技术背景

**BS-RoFormer (Band Split Roformer)** 是字节跳动 AI Labs 开发的 SOTA 音源分离模型，在 Sound Demixing Challenge 2023 获得冠军，SDR 达到 ~12.9dB。

**核心特点：**
- 使用 Band-Split 模块将复杂频谱图投影为子带级表示
- 采用轴向注意力机制（频率轴 + 时间轴）
- 支持立体声训练和多 Stem 输出
- 使用旋转位置编码 (RoPE) 提升训练效果

### 2.2 现有资源

项目中已存在：
- ✅ 模型权重：`models/model_bs_roformer_ep_317_sdr_12.9755.ckpt` (639MB)
- ✅ 模型配置：`models/model_bs_roformer_ep_317_sdr_12.9755.yaml`

配置文件关键参数：
```yaml
audio:
  sample_rate: 44100
  chunk_size: 352800  # 约 8 秒
  
model:
  dim: 512
  depth: 12
  stereo: true
  num_stems: 1        # 单 Stem 输出 (Vocals)
  
inference:
  batch_size: 1
  num_overlap: 4      # 重叠推理提升边缘质量
```

### 2.3 集成方案

**依赖库：**
```bash
pip install BS-RoFormer -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**核心实现思路：**

1. **模型加载**
   - 从 YAML 配置读取模型参数
   - 使用 `bs_roformer.BSRoformer` 实例化模型
   - 加载 `.ckpt` 权重到模型
   - 移动到 GPU 并设置 eval 模式

2. **音频预处理**
   - 使用 torchaudio 加载音频
   - 重采样到 44100Hz（如需要）
   - 分块处理长音频（chunk_size=352800，约 8 秒）
   - 使用 overlap 策略处理边界

3. **推理流程**
   - 输入波形 → STFT → 模型推理 → Mask 估计 → ISTFT → 输出波形
   - 支持 FP16 半精度加速（配置项 `use_fp16=True`）

4. **多 Stem 分离策略**
   - 当前权重为 Vocals 单 Stem 模型
   - 分离 Vocals 后，原始 - Vocals = Instrumental
   - 后续可下载 4-Stem 全分离权重实现 drums/bass/other

5. **输出格式**
   - 保存为 WAV 格式到 `output/{音频名}/stems/`
   - 返回路径字典供后续节点使用

### 2.4 技术要点

| 要点 | 说明 |
|------|------|
| 分块推理 | 长音频需分块，使用 overlap 避免边界失真 |
| 内存管理 | 单次推理约需 4-6GB 显存，需动态释放 |
| 设备适配 | 支持 CUDA/CPU 自动切换 |
| 采样率 | 必须使用 44100Hz，与模型训练一致 |

---

## 三、CLaMP 3 语义分析集成方案

### 3.1 技术背景

**CLaMP 3 (Contrastive Language-Audio-Music Pretraining 3)** 是最新的多模态音乐理解模型，支持 100+ 语言的跨模态检索。

**核心能力：**
- 🎵 Audio ↔ Text 检索（音频搜文本 / 文本搜音频）
- 🖼️ Image ↔ Music 检索
- 🏷️ Zero-Shot 分类（风格、情感、乐器识别）
- 📊 语义相似度计算

**模型地址：** `sander-wood/clamp3` (Hugging Face)

### 3.2 集成方案

**依赖安装：**
```bash
pip install transformers torch torchaudio -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**核心实现思路：**

1. **模型加载**
   - 从 Hugging Face 下载 CLaMP 3 预训练权重
   - 初始化时自动缓存到本地
   - 使用 SAAS 版本（音频优化版）

2. **描述符库预编码**
   - 加载 `data/descriptor_bank.json` 中的 160 个描述符
   - 使用 CLaMP 3 文本编码器预计算所有描述符的 Embedding
   - 缓存到 `.npy` 文件，避免重复计算

3. **音频编码**
   - 将输入音频编码为 768 维向量
   - 支持 `.mp3` / `.wav` 格式
   - 自动处理采样率转换

4. **语义检索**
   - 计算音频 Embedding 与所有描述符 Embedding 的余弦相似度
   - 按类别（mood/genre/instruments/texture）分组
   - 每个类别取 Top-K 个最相似的标签
   - 返回带置信度分数的 `SemanticTags` 对象

5. **分轨增强（可选）**
   - 对分离后的 Vocals/Drums 等单独分析
   - 融合多轨结果提升准确性

### 3.3 技术要点

| 要点 | 说明 |
|------|------|
| 模型下载 | 首次运行自动从 HuggingFace 下载约 1GB 权重 |
| Embedding 缓存 | 描述符库只需编码一次，后续直接加载 |
| 相似度计算 | 使用余弦相似度，阈值筛选高置信标签 |
| 多语言 | 支持中文描述符，可扩展描述符库 |

### 3.4 检索流程图

```
┌─────────────────────────────────────────────────────────┐
│                    语义检索流程                          │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  ┌─────────┐    CLaMP 3    ┌──────────────────┐        │
│  │ 音频文件 │ ──────────▶ │ Audio Embedding  │        │
│  └─────────┘    Encoder    │    (768-dim)     │        │
│                            └────────┬─────────┘        │
│                                     │                   │
│                                     ▼  余弦相似度       │
│                                                         │
│  ┌─────────────┐  CLaMP 3  ┌──────────────────┐        │
│  │ 描述符库     │ ───────▶ │ Text Embeddings  │        │
│  │ (160 tags)  │  Encoder  │  (160 × 768)     │        │
│  └─────────────┘           └────────┬─────────┘        │
│                                     │                   │
│                                     ▼                   │
│                          ┌──────────────────┐          │
│                          │  Top-K 标签       │          │
│                          │  + 置信度分数     │          │
│                          └──────────────────┘          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## 四、实施计划

### Phase 1: BS-RoFormer 集成

| 步骤 | 内容 | 预计工作量 |
|------|------|-----------|
| 1 | 添加 `BS-RoFormer` 依赖到 requirements.txt | 5 min |
| 2 | 在 `separator.py` 中实现 `load_model()` 真实加载逻辑 | 30 min |
| 3 | 实现分块推理 + overlap 策略 | 45 min |
| 4 | 实现多 Stem 输出（Vocals + Instrumental） | 20 min |
| 5 | 测试验证 + 错误处理 | 30 min |

### Phase 2: CLaMP 3 集成

| 步骤 | 内容 | 预计工作量 |
|------|------|-----------|
| 1 | 添加 CLaMP 3 相关依赖 | 5 min |
| 2 | 实现 CLaMP 3 模型加载器 | 30 min |
| 3 | 实现描述符库预编码 + 缓存 | 30 min |
| 4 | 实现音频编码 + 语义检索 | 45 min |
| 5 | 集成到 `semantic_reviewer.py` | 30 min |
| 6 | 测试验证 | 30 min |

---

## 五、风险与预案

| 风险 | 影响 | 应对措施 |
|------|------|----------|
| GPU 显存不足 | 推理失败 | 启用 FP16 / 自动回退 CPU |
| HuggingFace 下载慢 | 首次启动慢 | 使用镜像源 / 手动下载 |
| 模型版本不兼容 | 加载失败 | 锁定依赖版本 |

---

## 六、预期成果

集成完成后：

1. **音源分离**：输入任意 MP3/WAV，自动分离为 Vocals + Instrumental
2. **语义分析**：自动识别情感、风格、乐器、音色等标签，附带置信度
3. **端到端运行**：`python -m src.main analyze 卡农.mp3` 生成完整分析报告

---

**请审批后开始实施。**
