"""
è®¤çŸ¥ç»¼åˆå±‚ (The Analyst)
========================

ä½¿ç”¨ DeepSeek-Reasoner ç”Ÿæˆæœ€ç»ˆçš„éŸ³ä¹åˆ†ææŠ¥å‘Šã€‚
"""

import time
from pathlib import Path
from typing import Optional, Dict, Any

from rich.console import Console
from rich.markdown import Markdown

from src.config import config, OUTPUT_DIR
from src.schemas import AnalysisState, AnalysisResult, MusicalFeatures, SemanticTags

console = Console()


# === åˆ†ææŠ¥å‘Š Prompt æ¨¡æ¿ ===
ANALYST_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„éŸ³ä¹åˆ¶ä½œäººå’Œä¹è¯„äººï¼Œæ‹¥æœ‰æ•é”çš„å¬è§‰å’Œæ·±åšçš„ä¹ç†çŸ¥è¯†ã€‚
è¯·æ ¹æ®ä»¥ä¸‹ AI æå–çš„è¯¦ç»†éŸ³ä¹ç‰¹å¾æ•°æ®ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šã€æ·±åº¦ä¸”å……æ»¡æ´è§çš„éŸ³ä¹åˆ†ææŠ¥å‘Šã€‚

## 1. åŸºç¡€ä¿¡æ¯
- æ–‡ä»¶å: {filename}
- æ—¶é•¿: {duration}
- BPM: {bpm}
- è°ƒæ€§: {key}
- æ‹å·: {time_signature}

## 2. å’Œå£°ä¸æ—‹å¾‹åˆ†æ
- å’Œå¼¦è¿›è¡Œ: {chord_progression}

## 3. ç¼–æ›²ä¸é…å™¨ç»†èŠ‚ (åˆ†è½¨æ·±åº¦åˆ†æ)
{stems_detailed_analysis}

## 4. è¯­ä¹‰æ„ŸçŸ¥ (AI å¬æ„Ÿæ ‡ç­¾)
- æƒ…æ„Ÿæ°›å›´: {mood}
- é£æ ¼æµæ´¾: {genre}
- éŸ³è‰²è´¨æ„Ÿ: {texture}
- è¯†åˆ«ä¹å™¨: {instruments}

---

## å†™ä½œè¦æ±‚
è¯·ç»¼åˆä¸Šè¿°æ•°æ®ï¼Œæ’°å†™ä¸€ä»½ç»“æ„æ¸…æ™°çš„ Markdown æŠ¥å‘Šã€‚è¯·é¿å…ç®€å•ç½—åˆ—æ•°æ®ï¼Œè€Œæ˜¯å°†æ•°æ®è½¬åŒ–ä¸º**éŸ³ä¹æ€§çš„æè¿°**ã€‚

**æŠ¥å‘Šç»“æ„ï¼š**

1.  **æ•´ä½“å¬æ„Ÿä¸é£æ ¼å®šä½**
    *   ç»“åˆ BPMã€è°ƒæ€§å’Œé£æ ¼æ ‡ç­¾ï¼Œæè¿°æ›²ç›®çš„æ•´ä½“æ°›å›´ã€‚
    *   (ä¾‹å¦‚ï¼š128 BPM é…åˆ F# Minor è°ƒæ€§ï¼Œæ„å»ºäº†å…¸å‹çš„ Deep House é˜´éƒè€Œå¾‹åŠ¨çš„åŸºè°ƒ...)

2.  **ç¼–æ›²ä¸åˆ¶ä½œåˆ†æ**
    *   **æ ¸å¿ƒå¾‹åŠ¨**: åŸºäº Drums å’Œ Bass çš„å¯†åº¦ä¸æ´»è·ƒåº¦ï¼Œåˆ†æèŠ‚å¥ç»„çš„è¡¨ç°ï¼ˆå¦‚ï¼šç¨€ç–çš„é¼“ç‚¹é…åˆæ´»è·ƒçš„è´æ–¯çº¿...ï¼‰ã€‚
    *   **æ—‹å¾‹ä¸å’Œå£°**: åˆ†æ Vocals/Other çš„éŸ³åŸŸå’Œå¯†åº¦ï¼Œä»¥åŠå’Œå¼¦è¿›è¡Œçš„èµ°å‘å¸¦æ¥çš„æƒ…æ„Ÿå¼ åŠ›ã€‚
    *   **éŸ³å“è®¾è®¡**: ç»“åˆéŸ³è‰²è´¨æ„Ÿæ ‡ç­¾ï¼Œè¯„ä»·æ•´ä½“çš„æ··éŸ³é£æ ¼ï¼ˆå¦‚ï¼šLo-fi é¢—ç²’æ„Ÿã€ç©ºé—´æ„Ÿç­‰ï¼‰ã€‚

3.  **æƒ…æ„Ÿæ¼”è¿›ä¸é«˜æ½®**
    *   æ¨æµ‹éŸ³ä¹çš„æƒ…æ„Ÿå‘å±•æ›²çº¿ã€‚

4.  **åˆ¶ä½œäººè§†è§’çš„ä¸“ä¸šç‚¹è¯„**
    *   æŒ‡å‡ºæ›²ç›®çš„äº®ç‚¹ï¼ˆå¦‚ç‹¬ç‰¹çš„å’Œå¼¦æ›¿ä»£ã€ç²¾å½©çš„è´æ–¯ç¼–æ’ï¼‰ã€‚
    *   ç»™å‡ºåˆ¶ä½œä¸Šçš„æ”¹è¿›å»ºè®®ã€‚

è¯·ä¿æŒè¯­æ°”ä¸“ä¸šã€å®¢è§‚ä½†å¯Œæœ‰æ„ŸæŸ“åŠ›ï¼Œåƒä¸€ä½çœŸäººåœ¨è¯„ä»·è¿™é¦–æ­Œã€‚
"""


class MusicAnalyst:
    """
    éŸ³ä¹åˆ†æå¸ˆ
    
    æ±‡æ€»æ‰€æœ‰ä¸“å®¶çš„åˆ†æç»“æœï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå¸ˆ"""
        self.llm_client = None
        self._initialized = False
        
    def initialize(self) -> None:
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        if self._initialized:
            return
            
        console.print("[cyan]åˆå§‹åŒ–åˆ†æå¸ˆ...[/cyan]")
        
        if config.llm.api_key:
            try:
                from openai import OpenAI
                
                self.llm_client = OpenAI(
                    api_key=config.llm.api_key,
                    base_url=config.llm.base_url
                )
                console.print(f"[green]âœ“ LLM å®¢æˆ·ç«¯å·²è¿æ¥: {config.llm.model_name}[/green]")
                
            except ImportError:
                console.print("[yellow]âš  OpenAI åº“æœªå®‰è£…[/yellow]")
            except Exception as e:
                console.print(f"[red]LLM åˆå§‹åŒ–å¤±è´¥: {e}[/red]")
        else:
            console.print("[yellow]âš  æœªé…ç½® API Keyï¼Œå°†ä½¿ç”¨æ¨¡æ¿æŠ¥å‘Š[/yellow]")
            
        self._initialized = True
        
    def generate_report_from_data(
        self,
        audio_path: str,
        stems_paths: Dict[str, str],
        midi_data: Dict[str, Any],
        musical_features: Optional[MusicalFeatures],
        semantic_tags: Optional[SemanticTags]
    ) -> str:
        """
        ä»åˆ†ææ•°æ®ç”ŸæˆæŠ¥å‘Š
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            stems_paths: åˆ†è½¨è·¯å¾„å­—å…¸
            midi_data: MIDI æ•°æ®å­—å…¸
            musical_features: éŸ³ä¹ç‰¹å¾
            semantic_tags: è¯­ä¹‰æ ‡ç­¾
            
        Returns:
            Markdown æ ¼å¼çš„åˆ†ææŠ¥å‘Š
        """
        if not self._initialized:
            self.initialize()
            
        # æ ¼å¼åŒ– Prompt
        prompt = self._format_prompt_from_data(
            audio_path, stems_paths, midi_data, 
            musical_features, semantic_tags
        )
        
        console.print("\n[bold cyan]ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...[/bold cyan]")
        
        if self.llm_client:
            try:
                response = self.llm_client.chat.completions.create(
                    model=config.llm.model_name,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„éŸ³ä¹åˆ¶ä½œäººå’Œä¹è¯„äººã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=config.llm.temperature,
                    max_tokens=config.llm.max_tokens
                )
                
                report = response.choices[0].message.content
                console.print("[green]âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆ[/green]")
                return report
                
            except Exception as e:
                console.print(f"[red]LLM è°ƒç”¨å¤±è´¥: {e}[/red]")
                console.print("[yellow]ä½¿ç”¨æ¨¡æ¿æŠ¥å‘Š...[/yellow]")
                
        # æ¨¡æ¿æŠ¥å‘Šï¼ˆå½“ LLM ä¸å¯ç”¨æ—¶ï¼‰
        return self._generate_template_report_from_data(
            audio_path, stems_paths, midi_data,
            musical_features, semantic_tags
        )
        
    def _format_prompt_from_data(
        self,
        audio_path: str,
        stems_paths: Dict[str, str],
        midi_data: Dict[str, Any],
        musical_features: Optional[MusicalFeatures],
        semantic_tags: Optional[SemanticTags]
    ) -> str:
        """æ ¼å¼åŒ– Prompt"""
        filename = Path(audio_path).name
        
        # å‡†å¤‡å„é¡¹æ•°æ®
        duration = "æœªçŸ¥"
        if musical_features and musical_features.duration_seconds:
            mins = int(musical_features.duration_seconds // 60)
            secs = int(musical_features.duration_seconds % 60)
            duration = f"{mins}:{secs:02d}"
            
        bpm = f"{musical_features.bpm:.1f}" if musical_features and musical_features.bpm else "æœªæ£€æµ‹"
        key = musical_features.key if musical_features and musical_features.key else "æœªæ£€æµ‹"
        time_sig = musical_features.time_signature if musical_features else "4/4"
        
        # å’Œå¼¦è¿›è¡Œ
        chord_prog = "æœªæ£€æµ‹"
        if musical_features and musical_features.chord_progression:
            # ä»…å–å‰ 16 ä¸ªå’Œå¼¦å±•ç¤ºï¼Œé¿å… Prompt è¿‡é•¿
            chords = [c.chord_name for c in musical_features.chord_progression[:16]]
            chord_prog = " â†’ ".join(chords)
            if len(musical_features.chord_progression) > 16:
                chord_prog += " ..."
            
        # åˆ†è½¨è¯¦ç»†åˆ†æ
        stems_detailed_analysis = "æš‚æ— è¯¦ç»†åˆ†è½¨æ•°æ®"
        if musical_features and musical_features.stem_analyses:
            lines = []
            for stem_name, analysis in musical_features.stem_analyses.items():
                line = (
                    f"- **{stem_name.upper()}**: {analysis.description}\n"
                    f"  (å¯†åº¦: {analysis.note_density:.1f} notes/s, "
                    f"æ´»è·ƒåº¦: {analysis.active_ratio:.0%}, "
                    f"åŠ›åº¦: {analysis.average_velocity:.0f})"
                )
                lines.append(line)
            stems_detailed_analysis = "\n".join(lines)
        elif stems_paths:
             # å›é€€åˆ°ç®€å•åˆ—è¡¨
            stems_list = [f"- {stem}" for stem in stems_paths.keys()]
            stems_detailed_analysis = "\n".join(stems_list)
            
        # è¯­ä¹‰æ ‡ç­¾
        mood = ", ".join(semantic_tags.mood) if semantic_tags else "æœªåˆ†æ"
        genre = ", ".join(semantic_tags.genre) if semantic_tags else "æœªåˆ†æ"
        texture = ", ".join(semantic_tags.texture) if semantic_tags else "æœªåˆ†æ"
        instruments = ", ".join(semantic_tags.instruments) if semantic_tags else "æœªåˆ†æ"
        
        return ANALYST_PROMPT_TEMPLATE.format(
            filename=filename,
            duration=duration,
            bpm=bpm,
            key=key,
            time_signature=time_sig,
            chord_progression=chord_prog,
            stems_detailed_analysis=stems_detailed_analysis,
            mood=mood,
            genre=genre,
            texture=texture,
            instruments=instruments
        )
        
    def _generate_template_report_from_data(
        self,
        audio_path: str,
        stems_paths: Dict[str, str],
        midi_data: Dict[str, Any],
        musical_features: Optional[MusicalFeatures],
        semantic_tags: Optional[SemanticTags]
    ) -> str:
        """ç”Ÿæˆæ¨¡æ¿æŠ¥å‘Š"""
        filename = Path(audio_path).name
        
        genre_str = ", ".join(semantic_tags.genre) if semantic_tags else "æœªçŸ¥"
        mood_str = ", ".join(semantic_tags.mood) if semantic_tags else "æœªçŸ¥"
        texture_str = ", ".join(semantic_tags.texture) if semantic_tags else "æœªçŸ¥"
        
        duration_str = "æœªçŸ¥"
        if musical_features and musical_features.duration_seconds:
            duration_str = f"{musical_features.duration_seconds:.1f}ç§’"
            
        stems_list = "\n".join([f'- **{stem}**' for stem in stems_paths.keys()]) if stems_paths else "- æœªåˆ†ç¦»"
        
        return f"""# ğŸµ éŸ³ä¹åˆ†ææŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **æ–‡ä»¶**: {filename}
- **æ—¶é•¿**: {duration_str}

## æ•´ä½“å°è±¡
è¿™æ˜¯ä¸€é¦–å…·æœ‰ **{genre_str}** é£æ ¼ç‰¹å¾çš„æ›²ç›®ï¼Œæ•´ä½“æ°›å›´å‘ˆç°å‡º **{mood_str}** çš„æƒ…æ„Ÿè‰²å½©ã€‚

## ç¼–æ›²åˆ†æ
é€šè¿‡éŸ³æºåˆ†ç¦»æŠ€æœ¯ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºä»¥ä¸‹ä¹å™¨å±‚ï¼š
{stems_list}

## æŠ€æœ¯ç‰¹ç‚¹
- **èŠ‚å¥ç»“æ„**: æ ‡å‡† {musical_features.time_signature if musical_features else '4/4'} æ‹
- **è°ƒæ€§**: {musical_features.key if musical_features else 'å¾…åˆ†æ'}
- **é€Ÿåº¦**: {musical_features.bpm if musical_features else 'å¾…æ£€æµ‹'} BPM

## è¯­ä¹‰ç‰¹å¾
| ç»´åº¦ | æ ‡ç­¾ |
|------|------|
| æƒ…æ„Ÿ | {mood_str} |
| é£æ ¼ | {genre_str} |
| è´¨æ„Ÿ | {texture_str} |

---
*æŠ¥å‘Šç”± Poly-Muse Analyst è‡ªåŠ¨ç”Ÿæˆ*
"""


def export_result(
    state: AnalysisState, 
    output_path: Optional[Path] = None
) -> AnalysisResult:
    """
    å¯¼å‡ºæœ€ç»ˆåˆ†æç»“æœ
    
    Args:
        state: å®Œæˆåˆ†æçš„çŠ¶æ€ (TypedDict)
        output_path: å¯é€‰çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        æ ‡å‡†åŒ–çš„åˆ†æç»“æœå¯¹è±¡
    """
    audio_path = state.get("audio_path", "")
    stems_paths = state.get("stems_paths", {})
    musical_features_dict = state.get("musical_features")
    semantic_tags_dict = state.get("semantic_tags")
    analysis_report = state.get("analysis_report", "")
    
    # é‡å»º Pydantic æ¨¡å‹
    musical_features = None
    if musical_features_dict:
        musical_features = MusicalFeatures(**musical_features_dict)
        
    semantic_tags = None
    if semantic_tags_dict:
        semantic_tags = SemanticTags(**semantic_tags_dict)
    
    result = AnalysisResult(
        audio_structure={
            "stems_path": stems_paths
        },
        musical_features=musical_features,
        semantic_tags=semantic_tags,
        review=analysis_report
    )
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if output_path is None:
        output_path = OUTPUT_DIR / Path(audio_path).stem / "analysis_result.json"
        
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(result.model_dump_json(indent=2))
        
    # åŒæ—¶ä¿å­˜ Markdown æŠ¥å‘Š
    report_path = output_path.parent / "analysis_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(analysis_report)
        
    console.print(f"\n[green]âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path.parent}[/green]")
    
    return result
