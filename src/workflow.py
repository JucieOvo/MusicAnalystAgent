"""
LangGraph å·¥ä½œæµç¼–æ’
====================

å®šä¹‰éŸ³ä¹åˆ†æçš„å®Œæ•´å·¥ä½œæµçŠ¶æ€æœºã€‚
"""

from typing import Literal
from pathlib import Path

from langgraph.graph import StateGraph, END
from rich.console import Console
from rich.panel import Panel

from src.schemas import AnalysisState

console = Console()


def router_node(state: AnalysisState) -> AnalysisState:
    """
    è·¯ç”±èŠ‚ç‚¹ï¼šåˆ¤æ–­ä»»åŠ¡ç±»å‹
    """
    console.print(Panel.fit(
        f"[bold cyan]ğŸµ Poly-Muse Analyst[/bold cyan]\n"
        f"[dim]å¤šæ¨¡æ€éŸ³ä¹åˆ†ææ™ºèƒ½ä½“[/dim]",
        border_style="cyan"
    ))
    
    audio_path = state.get("audio_path", "")
    task_type = state.get("task_type", "full_analysis")
    
    console.print(f"\nğŸ“‚ è¾“å…¥æ–‡ä»¶: [green]{audio_path}[/green]")
    console.print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: [yellow]{task_type}[/yellow]")
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    errors = state.get("errors", [])
    if audio_path and not Path(audio_path).exists():
        errors = errors + [f"æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"]
        console.print(f"[red]âœ— æ–‡ä»¶ä¸å­˜åœ¨![/red]")
        return {"errors": errors}
        
    return {}  # ä¸éœ€è¦æ›´æ–°ä»»ä½•å­—æ®µ


def route_task(state: AnalysisState) -> Literal["full_analysis", "semantic_only", "end"]:
    """
    æ ¹æ®çŠ¶æ€å†³å®šè·¯ç”±
    """
    errors = state.get("errors", [])
    if errors:
        return "end"
        
    task_type = state.get("task_type", "full_analysis")
    if task_type == "semantic_only":
        return "semantic_only"
        
    return "full_analysis"


def separate_audio(state: AnalysisState) -> AnalysisState:
    """
    LangGraph èŠ‚ç‚¹å‡½æ•°ï¼šéŸ³æºåˆ†ç¦»
    """
    from src.agents.separator import AudioSeparator
    import time
    
    console.print("\n[bold magenta]â•â•â• å¬è§‰åˆ†ç¦»ä¸“å®¶ â•â•â•[/bold magenta]")
    
    start_time = time.time()
    audio_path = state.get("audio_path", "")
    
    try:
        separator = AudioSeparator()
        stems = separator.separate(Path(audio_path))
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²è·¯å¾„
        stems_paths = {stem.value: str(path) for stem, path in stems.items()}
        
        return {
            "stems_paths": stems_paths,
            "separation_complete": True,
            "processing_time": {"separation": time.time() - start_time}
        }
        
    except Exception as e:
        console.print(f"[red]âœ— åˆ†ç¦»å¤±è´¥: {e}[/red]")
        return {
            "errors": [f"åˆ†ç¦»å¤±è´¥: {str(e)}"],
            "separation_complete": False
        }


def transcribe_stems(state: AnalysisState) -> AnalysisState:
    """
    LangGraph èŠ‚ç‚¹å‡½æ•°ï¼šç¬¦å·è½¬å½•
    """
    from src.agents.transcriber import AudioTranscriber
    from src.schemas import StemType
    from src.config import OUTPUT_DIR
    import time
    
    console.print("\n[bold magenta]â•â•â• ç¬¦å·è½¬å½•ä¸“å®¶ â•â•â•[/bold magenta]")
    
    separation_complete = state.get("separation_complete", False)
    if not separation_complete:
        console.print("[yellow]âš  åˆ†ç¦»å°šæœªå®Œæˆï¼Œè·³è¿‡è½¬å½•[/yellow]")
        return {"transcription_complete": False}
        
    start_time = time.time()
    stems_paths = state.get("stems_paths", {})
    audio_path = state.get("audio_path", "")
    
    try:
        transcriber = AudioTranscriber()
        
        # è½¬æ¢è·¯å¾„æ ¼å¼
        stems_path_typed = {StemType(k): Path(v) for k, v in stems_paths.items()}
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = OUTPUT_DIR / Path(audio_path).stem / "midi"
        
        # è½¬å½•æ‰€æœ‰åˆ†è½¨
        midi_results = transcriber.transcribe_all_stems(stems_path_typed, output_dir)
        
        # åˆ†æéŸ³ä¹ç‰¹å¾
        features = transcriber.analyze_features(midi_results, stems_path_typed)
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        midi_data = {}
        for stem_type, midi in midi_results.items():
            midi_data[stem_type.value] = {
                "notes": [note.model_dump() for note in midi.notes],
                "tempo": midi.tempo
            }
            
        features_dict = features.model_dump() if features else None
        
        return {
            "midi_data": midi_data,
            "musical_features": features_dict,
            "transcription_complete": True,
            "processing_time": {"transcription": time.time() - start_time}
        }
        
    except Exception as e:
        console.print(f"[red]âœ— è½¬å½•å¤±è´¥: {e}[/red]")
        return {
            "errors": [f"è½¬å½•å¤±è´¥: {str(e)}"],
            "transcription_complete": False
        }


def analyze_semantics(state: AnalysisState) -> AnalysisState:
    """
    LangGraph èŠ‚ç‚¹å‡½æ•°ï¼šè¯­ä¹‰åˆ†æ
    """
    from src.agents.semantic_reviewer import SemanticAnalyzer
    import time
    
    console.print("\n[bold magenta]â•â•â• è¯­ä¹‰ç†è§£ä¸“å®¶ â•â•â•[/bold magenta]")
    
    start_time = time.time()
    audio_path = state.get("audio_path", "")
    stems_paths = state.get("stems_paths", {})
    
    try:
        analyzer = SemanticAnalyzer()
        
        # åˆ†æè¯­ä¹‰
        tags = analyzer.analyze(
            Path(audio_path),
            stems_paths if state.get("separation_complete") else None
        )
        
        return {
            "semantic_tags": tags.model_dump(),
            "semantic_complete": True,
            "processing_time": {"semantic": time.time() - start_time}
        }
        
    except Exception as e:
        console.print(f"[red]âœ— è¯­ä¹‰åˆ†æå¤±è´¥: {e}[/red]")
        return {
            "errors": [f"è¯­ä¹‰åˆ†æå¤±è´¥: {str(e)}"],
            "semantic_complete": False
        }


def generate_analysis(state: AnalysisState) -> AnalysisState:
    """
    LangGraph èŠ‚ç‚¹å‡½æ•°ï¼šç”Ÿæˆåˆ†ææŠ¥å‘Š
    """
    from src.agents.analyst import MusicAnalyst
    from src.schemas import MusicalFeatures, SemanticTags
    import time
    
    console.print("\n[bold magenta]â•â•â• è®¤çŸ¥ç»¼åˆå±‚ â•â•â•[/bold magenta]")
    
    start_time = time.time()
    
    try:
        analyst = MusicAnalyst()
        
        # é‡æ„çŠ¶æ€ç”¨äºæŠ¥å‘Šç”Ÿæˆ
        musical_features = state.get("musical_features")
        semantic_tags = state.get("semantic_tags")
        
        if musical_features:
            musical_features = MusicalFeatures(**musical_features)
        if semantic_tags:
            semantic_tags = SemanticTags(**semantic_tags)
            
        report = analyst.generate_report_from_data(
            audio_path=state.get("audio_path", ""),
            stems_paths=state.get("stems_paths", {}),
            midi_data=state.get("midi_data", {}),
            musical_features=musical_features,
            semantic_tags=semantic_tags
        )
        
        return {
            "analysis_report": report,
            "processing_time": {"analysis": time.time() - start_time}
        }
        
    except Exception as e:
        console.print(f"[red]âœ— æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}[/red]")
        return {"errors": [f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"]}


def create_analysis_graph() -> StateGraph:
    """
    åˆ›å»ºéŸ³ä¹åˆ†æå·¥ä½œæµå›¾
    
    å·¥ä½œæµç»“æ„ (é¡ºåºæ‰§è¡Œä»¥é¿å…å¹¶å‘é—®é¢˜):
    
        [START]
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Router  â”‚ â”€â”€ åˆ¤æ–­ä»»åŠ¡ç±»å‹
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚Separatorâ”‚ â”€â”€ éŸ³æºåˆ†ç¦» (BS-RoFormer)
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚Transcri â”‚ â”€â”€ ç¬¦å·è½¬å½• (Basic Pitch)
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚Semantic â”‚ â”€â”€ è¯­ä¹‰åˆ†æ (CLaMP 3)
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Analyst â”‚ â”€â”€ ç”ŸæˆæŠ¥å‘Š (LLM)
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚
           â–¼
         [END]
    """
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AnalysisState)
    
    # === æ·»åŠ èŠ‚ç‚¹ ===
    workflow.add_node("router", router_node)
    workflow.add_node("separator", separate_audio)
    workflow.add_node("transcriber", transcribe_stems)
    workflow.add_node("semantic", analyze_semantics)
    workflow.add_node("analyst", generate_analysis)
    
    # === è®¾ç½®å…¥å£ ===
    workflow.set_entry_point("router")
    
    # === æ·»åŠ è¾¹ (é¡ºåºæ‰§è¡Œ) ===
    workflow.add_conditional_edges(
        "router",
        route_task,
        {
            "full_analysis": "separator",
            "semantic_only": "semantic",
            "end": END
        }
    )
    
    # é¡ºåºæ‰§è¡Œ: separator -> transcriber -> semantic -> analyst
    workflow.add_edge("separator", "transcriber")
    workflow.add_edge("transcriber", "semantic")
    workflow.add_edge("semantic", "analyst")
    
    # åˆ†æå®Œæˆåç»“æŸ
    workflow.add_edge("analyst", END)
    
    return workflow


class MusicAnalysisPipeline:
    """
    éŸ³ä¹åˆ†æç®¡é“
    
    å°è£… LangGraph å·¥ä½œæµçš„é«˜çº§æ¥å£ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡é“"""
        self.graph = create_analysis_graph()
        self.app = self.graph.compile()
        
    def analyze(
        self,
        audio_path: str | Path,
        task_type: str = "full_analysis"
    ) -> AnalysisState:
        """
        æ‰§è¡Œå®Œæ•´çš„éŸ³ä¹åˆ†æ
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            task_type: ä»»åŠ¡ç±»å‹ ("full_analysis" | "semantic_only")
            
        Returns:
            å®Œæˆçš„åˆ†æçŠ¶æ€
        """
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state: AnalysisState = {
            "audio_path": str(Path(audio_path).absolute()),
            "task_type": task_type,
            "stems_paths": {},
            "separation_complete": False,
            "midi_data": {},
            "transcription_complete": False,
            "musical_features": None,
            "semantic_tags": None,
            "semantic_complete": False,
            "analysis_report": None,
            "errors": [],
            "processing_time": {}
        }
        
        # æ‰§è¡Œå·¥ä½œæµ
        console.print("\n[bold]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bold]")
        console.print("[bold cyan]      å¼€å§‹éŸ³ä¹åˆ†æå·¥ä½œæµ[/bold cyan]")
        console.print("[bold]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bold]\n")
        
        import time
        start = time.time()
        
        # è¿è¡Œå›¾
        final_state = None
        for output in self.app.stream(initial_state):
            # æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º
            for node_name, node_state in output.items():
                console.print(f"[dim]å®ŒæˆèŠ‚ç‚¹: {node_name}[/dim]")
                final_state = node_state
                
        total_time = time.time() - start
        
        # æ‰“å°æ€»ç»“
        console.print("\n[bold]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bold]")
        console.print(f"[bold green]      åˆ†æå®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}s[/bold green]")
        console.print("[bold]â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bold]")
        
        if final_state and final_state.get("processing_time"):
            console.print("\n[dim]å„é˜¶æ®µè€—æ—¶:[/dim]")
            for stage, duration in final_state.get("processing_time", {}).items():
                console.print(f"  {stage}: {duration:.2f}s")
                
        return final_state
        
    def analyze_and_export(
        self,
        audio_path: str | Path,
        output_dir: str | Path | None = None
    ):
        """
        åˆ†æå¹¶å¯¼å‡ºç»“æœ
        """
        state = self.analyze(audio_path)
        
        if state and state.get("analysis_report"):
            from src.agents.analyst import export_result
            result = export_result(state, output_dir)
            return result
        else:
            console.print("[red]åˆ†ææœªå®Œæˆï¼Œæ— æ³•å¯¼å‡º[/red]")
            return None


# === ç®€åŒ–æ¥å£ ===
def analyze_music(audio_path: str | Path) -> AnalysisState:
    """
    å¿«é€Ÿåˆ†ææ¥å£
    
    ç”¨æ³•:
        from src.workflow import analyze_music
        result = analyze_music("path/to/audio.mp3")
    """
    pipeline = MusicAnalysisPipeline()
    return pipeline.analyze(audio_path)
