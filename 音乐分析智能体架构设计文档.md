# **Poly-Muse Analyst: 多模态音乐分析智能体架构设计文档**

**版本:** 1.0

**日期:** 2026年2月

**状态:** 待实施

## **1\. 项目愿景 (Project Vision)**

构建一个基于 LangGraph 的多专家智能体系统，旨在将非结构化的音乐音频转化为结构化的深度分析报告。系统不依赖单一的“黑盒”大模型，而是通过调度 **SOTA（State-of-the-Art）信号处理模型** 与 **多模态理解模型**，实现对音乐音频的**物理层**（分轨）、**符号层**（乐谱）和**语义层**（情感与风格）的全维解析。

## **2\. 系统核心架构 (System Architecture)**

系统采用 **“路由-专家” (Router-Expert)** 拓扑结构。主控制器（Supervisor）负责接收用户指令并维护全局状态（State），各子 Agent 独立运行并回传结果。

### **2.1 技术栈选型**

| 模块层级 | 核心模型/工具 | 选型依据 (基于当前 SOTA) |
| :---- | :---- | :---- |
| **听觉分离层** | **BS-RoFormer** | 当前 MSS 领域冠军模型 (SDR \~9.8dB)，优于 Hybrid Demucs v4，尤其在密集频谱分离上表现卓越。 |
| **符号转录层** | **Basic Pitch** | Spotify 开源的轻量级模型，支持多音高检测，对不同乐器的泛化性强，适合从分轨中提取 MIDI。 |
| **语义检索层** | **CLaMP 3** | 支持 101 种语言的跨模态检索，用于将音频特征映射到文本描述符空间。 |
| **编排与推理** | **LangGraph** | 用于构建有向循环图 (DAG) 工作流，管理 Agent 间的状态传递。 |
| **认知综合层** | **DeepSeek-Reasoner** | 负责最终的“乐评人”角色，清洗数据并生成自然语言报告。 |

## ---

**3\. 详细模块设计 (Component Specifications)**

### **3.1 听觉分离专家 (The Separator)**

* **输入:** 原始混音音频文件 (WAV/MP3/FLAC)。  
* **核心引擎:** BS-RoFormer (Band-Split RoPE Transformer)。  
* **执行逻辑:**  
  1. **预处理:** 将音频重采样并转换为频谱图。  
  2. **频带拆分:** 将频谱划分为多个子带，独立进行特征提取。  
  3. **RoPE 推理:** 利用旋转位置编码处理长序列依赖，分离出各乐器掩码。  
  4. **合成:** 逆变换生成独立波形。  
* **输出产物:** 4-6 个独立音轨文件 (Vocals, Drums, Bass, Other, etc.)。

### **3.2 符号转录专家 (The Transcriber)**

* **输入:** 上一步生成的“独立音轨” (Stems)，而非原始混音。  
* **核心引擎:** Basic Pitch。  
* **执行策略:**  
  * **针对性转录:** 仅对 Drums 轨提取节奏 MIDI，仅对 Bass 轨提取低音 MIDI，仅对 Vocals 轨提取旋律 MIDI。这比直接转录混音准确率高出数倍。  
* **输出产物:** 分轨 MIDI 文件 (.mid) 及 JSON 格式的音符事件列表 (Note On/Off, Velocity)。

### **3.3 语义理解专家 (The Semantic Reviewer)**

本模块采用 **RAG-Reviewer (检索增强评论)** 架构，由以下两部分组成：

#### **A. 描述符库 (Descriptor Bank) \- *静态资产***

预先构建的高质量音乐术语库（JSON格式），包含约 10,000+ 个标签：

* **情感类:** 忧郁 (Melancholic), 激昂 (Euphoric), 压抑 (Oppressive)...  
* **风格流派:** 蒸汽波 (Vaporwave), 硬波普 (Hard Bop), 陷阱音乐 (Trap)...  
* **音色质感:** 失真 (Distorted), 空灵 (Ethereal), Lo-fi 颗粒感 (Lo-fi crackle)...

#### **B. 检索匹配 (Retrieval) \- *动态推理***

* **输入:** 原始音频或特定分轨。  
* **核心引擎:** CLaMP 3。  
* **执行逻辑:**  
  1. **编码:** 计算音频的 CLaMP Embedding。  
  2. **检索:** 计算音频向量与“描述符库”中所有文本向量的余弦相似度。  
  3. **筛选:** 提取 Top-20 个最高置信度的标签。  
* **输出产物:** 语义标签列表 (例如: \["Sad", "Reverb piano", "Slow tempo", "Jazz fusion"\])。

## ---

**4\. 全局工作流 (Orchestration Workflow)**

以下定义 LangGraph 的状态机流转逻辑：

**全局状态 (State Schema):**

包含：原始音频路径、分轨路径字典、MIDI数据字典、语义标签列表、最终报告文本。

1. **节点 0: 初始化 (Router)**  
   * 接收用户音频，判断任务类型。若需全量分析，触发分离节点。  
2. **节点 A: 分离 (Separation Node)**  
   * 调用 BS-RoFormer。  
   * 更新状态：写入 分轨路径字典。  
3. **节点 B: 并行处理 (Parallel Execution)**  
   * **B1 (转录):** 读取分轨 \-\> Basic Pitch \-\> 更新 MIDI数据。  
   * **B2 (语义):** 读取音频 \-\> CLaMP 3 \-\> 检索描述库 \-\> 更新 语义标签。  
4. **节点 C: 综合分析 (Analyst Node)**  
   * **输入:** 汇总是 B1 (BPM, 调性, 和弦级数) 和 B2 (风格, 情感标签)。  
   * **Prompt 策略:**"你是一位专业的音乐制作人。根据以下客观数据：\[BPM: 128\]、\[调性: C Minor\]、\[乐器构成: 强烈的失真贝斯\]、\[风格标签: Techno, Dark\]... 请撰写一份深度的音乐分析报告，包含制作技巧分析和听感描述。"  
   * **输出:** 最终 Markdown 报告。

## ---

**5\. 实施路线图 (Implementation Roadmap)**

### **第一阶段：基础设施 (Infrastructure) \- MVP**

* **环境搭建:** 配置 Python 环境，安装 PyTorch, Torchaudio。  
* **模型部署:** 下载 BS-RoFormer 预训练权重 (sdr-9.8dB版) 和 Basic Pitch 库。  
* **单元测试:** 编写独立的 Python 脚本测试每个模型对单个文件的处理能力。

### **第二阶段：Agent 封装 (Agentification)**

* **工具化:** 将上述模型封装为 LangChain Tools (输入输出标准化)。  
* **图构建:** 使用 LangGraph 定义状态图，连接各个工具。  
* **描述库构建:** 生成或爬取首批 1000 个高频音乐描述词，建立向量索引。

### **第三阶段：集成与优化 (Integration)**

* **LLM 接入:** 调试 Prompt，确保 LLM 能准确理解 JSON 格式的乐理数据。  
* **性能优化:** 对 BS-RoFormer 进行半精度 (FP16) 推理加速。  
* **前端接口:** (可选) 提供一个简单的 Streamlit 界面用于上传和展示。

## ---

**6\. 数据输出标准 (Output Specifications)**

系统最终将生成一个包含所有元数据的 JSON 对象，示例如下：

* **Audio Structure:**  
  * stems\_path: { "vocals": "/path/to/vocal.wav", ... }  
* **Musical Features:**  
  * bpm: 124  
  * key: "F\# Minor"  
  * chord\_progression: \["vi", "IV", "I", "V"\]  
* **Semantic Tags:**  
  * mood: \["Energetic", "Tense"\]  
  * genre: \["Synthwave", "Cyberpunk"\]  
* **Review:** "本曲目展现了典型的 Synthwave 风格，Bass 分轨的侧链压缩感极强（由 BS-RoFormer 分离确认），旋律线使用了大混响的锯齿波合成器..."